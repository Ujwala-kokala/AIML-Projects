{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uplV5P3KSuje",
        "outputId": "dee30ae0-5007-4fd3-dd1c-85114ad541d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dWs48xTewsP",
        "outputId": "7d0aecd6-5a68-4d2d-8aef-92b976d52752",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Mount google colab to drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJtOh6kg6b6",
        "outputId": "acddac2c-5865-4a0b-9a7c-ff076d4660f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Import imdb dataset from keras\n",
        "# Get train set and test set with 10000 most frequent words.\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "(X_train,y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSLHgVtMjz0v"
      },
      "source": [
        "#Pad each sentence to be of same length of 300\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = 300)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = 300)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxo9oyLdqngn",
        "outputId": "cdce0204-859c-4139-b649-8924429ca762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print shape of features \n",
        "\n",
        "print('X_train', X_train.shape)\n",
        "print('y_train', y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train (25000, 300)\n",
            "y_train (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnwrNVGeHSDz",
        "outputId": "d67f1080-4659-4804-c5b6-3739dd8d7a9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print shape of labels\n",
        "\n",
        "print('X_test', X_test.shape)\n",
        "print('y_test', y_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_test (25000, 300)\n",
            "y_test (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKNZQSPVP0aL",
        "outputId": "84696abc-2ca3-4711-fa19-48841ecca46a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print one value of feature\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    1   14\n",
            "   22   16   43  530  973 1622 1385   65  458 4468   66 3941    4  173\n",
            "   36  256    5   25  100   43  838  112   50  670    2    9   35  480\n",
            "  284    5  150    4  172  112  167    2  336  385   39    4  172 4536\n",
            " 1111   17  546   38   13  447    4  192   50   16    6  147 2025   19\n",
            "   14   22    4 1920 4613  469    4   22   71   87   12   16   43  530\n",
            "   38   76   15   13 1247    4   22   17  515   17   12   16  626   18\n",
            "    2    5   62  386   12    8  316    8  106    5    4 2223 5244   16\n",
            "  480   66 3785   33    4  130   12   16   38  619    5   25  124   51\n",
            "   36  135   48   25 1415   33    6   22   12  215   28   77   52    5\n",
            "   14  407   16   82    2    8    4  107  117 5952   15  256    4    2\n",
            "    7 3766    5  723   36   71   43  530  476   26  400  317   46    7\n",
            "    4    2 1029   13  104   88    4  381   15  297   98   32 2071   56\n",
            "   26  141    6  194 7486   18    4  226   22   21  134  476   26  480\n",
            "    5  144   30 5535   18   51   36   28  224   92   25  104    4  226\n",
            "   65   16   38 1334   88   12   16  283    5   16 4472  113  103   32\n",
            "   15   16 5345   19  178   32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhKfTlIOdL4Q",
        "outputId": "5638f2f8-8761-4085-f34b-6fb466ed9424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_train[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
            "  194 1153  194 8255   78  228    5    6 1463 4369 5012  134   26    4\n",
            "  715    8  118 1634   14  394   20   13  119  954  189  102    5  207\n",
            "  110 3103   21   14   69  188    8   30   23    7    4  249  126   93\n",
            "    4  114    9 2300 1523    5  647    4  116    9   35 8163    4  229\n",
            "    9  340 1322    4  118    9    4  130 4901   19    4 1002    5   89\n",
            "   29  952   46   37    4  455    9   45   43   38 1543 1905  398    4\n",
            " 1649   26 6853    5  163   11 3215    2    4 1153    9  194  775    7\n",
            " 8255    2  349 2637  148  605    2 8003   15  123  125   68    2 6853\n",
            "   15  349  165 4362   98    5    4  228    9   43    2 1157   15  299\n",
            "  120    5  120  174   11  220  175  136   50    9 4373  228 8255    5\n",
            "    2  656  245 2350    5    4 9837  131  152  491   18    2   32 7464\n",
            " 1212   14    9    6  371   78   22  625   64 1382    9    8  168  145\n",
            "   23    4 1690   15   16    4 1355    5   28    6   52  154  462   33\n",
            "   89   78  285   16  145   95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8PWviCfcdwZ",
        "outputId": "d8d52906-6bc5-4d06-b5f7-1b8f5d5f99b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print one value of feature\n",
        "# output '0' indicate 'NEGATIVE' sentiment\n",
        "print(y_train[50])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTJfNVuodmXA",
        "outputId": "16db6935-7627-4cce-fecc-73ab3ddfff18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print one value of label\n",
        "# output '1' indicate 'POSITIVE' sentiment\n",
        "print(y_test[100])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNxdIW3lkEfe",
        "outputId": "da733111-8395-4dbe-d70b-60898eb6cfe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Decode the feature value to get original sentence\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value,key) for key, value in word_index.items()])\n",
        "decoded = \" \".join([reverse_word_index.get(i-3, \"#\") for i in X_train[91]])\n",
        "print(decoded)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "the strange set of brother's sisters who are just downright unlikeable so far removed from reality that any tension or mystery that the simplistic # story could have achieved is sorely missing then there's the awful twist ending that you can guess within the first 10 minutes it's boring to watch it's poorly paced it's just a chore to even think about it please someone save me as this is really bad stuff i could go on all day about how bad blood legacy is i really could br br director # was either working with a none existent budget or judging by this he shouldn't have even been directing traffic the entire film looks ugly it's poorly photographed there is no atmosphere or scares the blood gore is tame there's an axe in a head a decapitated head a scene when someone is # to death by # the best murder when someone's face is eaten by # however there are question marks over this scene so there's the victim right there's the tank of # right victims head is placed in # tank right # eat victims face right water remains crystal clear despite said victim having his face eaten # where's the blood br br technically blood legacy is terrible it looks awful the sound was obviously shot live it's # hard to hear which considering the terrible dialogue is maybe a # in disguise the acting was not going to win anyone any awards that's for sure the least said about it the better br br blood legacy is an awful film there really isn't a single positive aspect to it or if there is i can't think of it do yourself a favour don't bother with this one there are much better films out there\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se9FT1TbxUMU",
        "outputId": "03c6145a-64c5-4bcb-96d9-8cdf1c97b9dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_train[91])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7ymB4LXh91M"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten, TimeDistributed, Bidirectional"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaY9p-nSxboZ"
      },
      "source": [
        "# Define model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = 10000, output_dim = 100, input_length = 300))\n",
        "model.add(Bidirectional(LSTM(units=100, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(100, activation = 'relu')))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeXbnKk0pohJ"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4j9AGhlqsad",
        "outputId": "a1a06ea4-a294-4a9c-de2c-35b14faec36f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 300, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 300, 200)          160800    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 300, 100)          20100     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 30000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 30001     \n",
            "=================================================================\n",
            "Total params: 1,210,901\n",
            "Trainable params: 1,210,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dFnw3lxq4GS",
        "outputId": "394f1991-2d7e-44e9-c801-580edc281df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fit the model\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size = 32, epochs = 10, verbose = 1, validation_data= (X_test, y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 40s 51ms/step - loss: 0.3359 - accuracy: 0.8451 - val_loss: 0.2555 - val_accuracy: 0.8932\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.1700 - accuracy: 0.9354 - val_loss: 0.2759 - val_accuracy: 0.8878\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.1016 - accuracy: 0.9621 - val_loss: 0.3893 - val_accuracy: 0.8785\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 0.4790 - val_accuracy: 0.8766\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.5981 - val_accuracy: 0.8736\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.7756 - val_accuracy: 0.8677\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.7980 - val_accuracy: 0.8729\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.8400 - val_accuracy: 0.8741\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.8690 - val_accuracy: 0.8736\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.9462 - val_accuracy: 0.8702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-XFEq_htJar",
        "outputId": "56e8ee2c-1614-4272-8b7e-d55ed78dd70e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate the model\n",
        "\n",
        "result = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 10s 12ms/step - loss: 0.9462 - accuracy: 0.8702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8lM_lOw3SUE",
        "outputId": "de5a624c-ef61-4949-f350-8e9dfcd28a64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Predict one sample with model.predict\n",
        "\n",
        "text_neg = X_train[55]\n",
        "text_pos = X_train[10]\n",
        "texts = (text_neg, text_pos)\n",
        "padded_texts = sequence.pad_sequences(texts, maxlen=300, value = 0.0) # 0.0 because it corresponds with <PAD>\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.predict(padded_texts)\n",
        "print(predictions)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.6428271e-08]\n",
            " [1.0000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYt9EtH8IWRB",
        "outputId": "3f7aeb7f-f376-44a3-e75b-c97bee2fd468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value,key) for key, value in word_index.items()])\n",
        "decoded = \" \".join([reverse_word_index.get(i-3, \"#\") for i in X_train[55]])\n",
        "print(decoded)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "to be exact physical # their past # br br maybe kubrick didn't care about his storyline maybe only wanted to evoke a mood of horror whatever the case the film tries to # its narrative # to have it both ways rational and supernatural as a result the story is a mess this movie hasn't improved with age and it certainly doesn't improve with repeated viewings br br i don't deny that a few moments of fear # and general creepiness are scattered throughout this long long film but those # # # blood seen repeatedly in little # visions are absurd and laughable and jack # infamous tag lines wendy i'm home and # johnny merely # the movie's dramatic tension and # its narrative energy i know i sat in the theater and heard the audience laugh in comic relief # glad we don't have to take this stuff seriously finally kubrick is completely at sea or else utterly cynical during those scenes in which wendy wanders around the empty hotel while her husband tries to # their son a # full of # guests all sitting there dead in their party hats # now i really am afraid br br given jack # brilliance over the years one can only assume that he gave just the sort of # rolling # # scenery # performance that the director wanted the performance of shelley duvall as a sort of female version of don # in the ghost and mr chicken is best passed over in silence br br this movie simply doesn't succeed not as an adaptation not on its own terms it probably merits a 3 out of 10 but i'm giving it a 1 because it has been so # over rated in this forum\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cENa1uYFIfFh",
        "outputId": "9ca129c2-5288-4f21-bf02-d0dbfb22a7c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value,key) for key, value in word_index.items()])\n",
        "decoded = \" \".join([reverse_word_index.get(i-3, \"#\") for i in X_train[10]])\n",
        "print(decoded)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a short while in the cell together they stumble upon a hiding place in the wall that contains an old # after # part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that # makes the best of it's # as despite it's # the film never actually feels restrained and manages to flow well throughout director eric # provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell # that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really # people and this film proves that as the director # that we can never really be sure of exactly what is round the corner and this helps to ensure that # actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall # is a truly great horror film and one of the best of the decade highly recommended viewing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFAigOQbIprE"
      },
      "source": [
        "# The model built has predicted the sentiment correctly. We can check by using decoded text. \n",
        "# Negative review if predicted value is in between 0 - 0.5\n",
        "# Positive review if predicted value is in between 0.5 - 1\n",
        "# The model got  max accuracy of 99% and loss is 0.01%."
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}